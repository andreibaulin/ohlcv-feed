name: Rebuild OHLCV Feed (GitHub Pages)

on:
  workflow_dispatch:
    inputs:
      tail_lines:
        description: "Tail lines for *_tailN.txt (e.g. 200/500/1000)"
        required: true
        default: "500"
  schedule:
    - cron: "*/30 * * * *"   # каждые 30 минут

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Generate site (from scratch)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p _site/ohlcv/binance

          python - <<'PY'
          import json, os, time, datetime, urllib.parse, urllib.request
          from urllib.error import HTTPError, URLError

          # ===== CONFIG =====
          REPO_PAGES_BASE = "https://andreibaulin.github.io/ohlcv-feed"
          OUT_DIR = "_site/ohlcv/binance"
          os.makedirs(OUT_DIR, exist_ok=True)

          SYMBOLS = ["BTCUSDT","ETHUSDT","SOLUSDT","BNBUSDT","LINKUSDT"]
          TFS = {
            "H1": "1h",
            "H4": "4h",
            "D1": "1d",
            "W1": "1w",
          }

          # schedule запускается без inputs -> берём дефолт
          tail_env = os.environ.get("TAIL_LINES")
          if not tail_env or not tail_env.strip():
            tail_env = "500"
          TAIL = int(tail_env)

          # market-data-only endpoint (часто обходит 451 на api.binance.com)
          KLINES_BASE = "https://data-api.binance.vision/api/v3/klines"

          def fetch_klines(symbol: str, interval: str, limit: int = 1000):
            qs = urllib.parse.urlencode({"symbol": symbol, "interval": interval, "limit": str(limit)})
            url = f"{KLINES_BASE}?{qs}"
            last_err = None
            for _ in range(8):
              try:
                req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
                with urllib.request.urlopen(req, timeout=25) as r:
                  data = r.read().decode("utf-8")
                return json.loads(data)
              except (HTTPError, URLError, TimeoutError) as e:
                last_err = e
                time.sleep(1.5)
            raise RuntimeError(f"Failed to fetch klines {symbol} {interval}: {last_err}")

          def write_txt(path: str, klines):
            # open_time,open,high,low,close,volume,close_time
            lines = []
            for k in klines:
              lines.append(f"{k[0]},{k[1]},{k[2]},{k[3]},{k[4]},{k[5]},{k[6]}")
            with open(path, "w", encoding="utf-8") as f:
              f.write("\n".join(lines) + "\n")

          def tail_lines(lines, n):
            return lines[-n:] if len(lines) > n else lines

          def ms_to_utc(ms: int) -> str:
            return datetime.datetime.utcfromtimestamp(ms/1000).strftime("%Y-%m-%d %H:%M:%SZ")

          # ===== GENERATE TXT + TAIL =====
          for sym in SYMBOLS:
            for tf, interval in TFS.items():
              kl = fetch_klines(sym, interval, limit=1000)

              full_path = os.path.join(OUT_DIR, f"{sym}_{tf}.txt")
              write_txt(full_path, kl)

              with open(full_path, "r", encoding="utf-8") as f:
                raw = [ln.rstrip("\n") for ln in f.readlines() if ln.strip()]

              tpath = os.path.join(OUT_DIR, f"{sym}_{tf}_tail{TAIL}.txt")
              with open(tpath, "w", encoding="utf-8") as f:
                f.write("\n".join(tail_lines(raw, TAIL)) + "\n")

          updated_utc = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

          # ===== symbols.json =====
          symbols_json = {
            "tfs": list(TFS.keys()),
            "updated_utc": updated_utc,
            "symbols": SYMBOLS,
            "base_url": f"{REPO_PAGES_BASE}/ohlcv/binance/"
          }
          with open(os.path.join(OUT_DIR, "symbols.json"), "w", encoding="utf-8") as f:
            json.dump(symbols_json, f, ensure_ascii=False, indent=2)
            f.write("\n")

          # ===== core5_latest.json (PACK) =====
          pack = {
            "meta": {
              "source": "Binance Spot market-data-only (data-api.binance.vision) /api/v3/klines",
              "generated_utc": updated_utc,
              "tail_lines": TAIL,
              "symbols": SYMBOLS,
              "tfs": list(TFS.keys())
            },
            "data": {}
          }

          for sym in SYMBOLS:
            pack["data"][sym] = {}
            for tf in TFS.keys():
              tpath = os.path.join(OUT_DIR, f"{sym}_{tf}_tail{TAIL}.txt")
              with open(tpath, "r", encoding="utf-8") as f:
                rows = [ln.strip().split(",") for ln in f.readlines() if ln.strip()]
              # pack свеча: [t,o,h,l,c,v]
              pack["data"][sym][tf] = [
                [int(r[0]), float(r[1]), float(r[2]), float(r[3]), float(r[4]), float(r[5])]
                for r in rows
              ]

          # Компактный JSON (для сайта), а читаемый текст — отдельным файлом ниже
          with open(os.path.join(OUT_DIR, "core5_latest.json"), "w", encoding="utf-8") as f:
            json.dump(pack, f, ensure_ascii=False)
            f.write("\n")

          # ===== health.txt (короткий, железно читается) =====
          health_path = os.path.join(OUT_DIR, "health.txt")
          with open(health_path, "w", encoding="utf-8") as hf:
            hf.write(f"generated_utc={updated_utc} tail={TAIL}\n")
            for sym in SYMBOLS:
              for tf in TFS.keys():
                arr = pack["data"][sym][tf]
                last = arr[-1]
                t, o, h, l, c, v = last
                hf.write(f"{sym} {tf} last_open_utc={ms_to_utc(t)} close={c} volume={v}\n")

          # ===== core5_latest_pretty.txt (text/plain с переносами) =====
          pretty_path = os.path.join(OUT_DIR, "core5_latest_pretty.txt")
          with open(pretty_path, "w", encoding="utf-8") as pf:
            pf.write(json.dumps(pack, ensure_ascii=False, indent=2))
            pf.write("\n")

          # ===== bootstrap.txt =====
          with open(os.path.join(OUT_DIR, "bootstrap.txt"), "w", encoding="utf-8") as f:
            f.write("OHLCVFEED_BOOTSTRAP_20260207\n\n")
            f.write("# MAIN\n")
            f.write(f"{REPO_PAGES_BASE}/ohlcv/binance/health.txt\n")
            f.write(f"{REPO_PAGES_BASE}/ohlcv/binance/core5_latest_pretty.txt\n\n")

            f.write("# PACK / manifest\n")
            f.write("core5_latest:\n")
            f.write(f"{REPO_PAGES_BASE}/ohlcv/binance/core5_latest.json\n\n")
            f.write("symbols:\n")
            f.write(f"{REPO_PAGES_BASE}/ohlcv/binance/symbols.json\n\n")

            for sym in SYMBOLS:
              f.write(f"# {sym} (H1/H4/D1/W1) tail{TAIL}\n")
              for tf in TFS.keys():
                f.write(f"{REPO_PAGES_BASE}/ohlcv/binance/{sym}_{tf}_tail{TAIL}.txt\n")
              f.write("\n")

          # ===== start.html + index.html =====
          start_html = """<!doctype html>
          <html>
            <head>
              <meta charset="utf-8">
              <title>OHLCVFEED_BOOTSTRAP_20260207</title>
              <meta name="robots" content="index,follow">
            </head>
            <body>
              <h1>OHLCVFEED_BOOTSTRAP_20260207</h1>
              <ul>
                <li><a href="ohlcv/binance/health.txt">health.txt</a></li>
                <li><a href="ohlcv/binance/core5_latest_pretty.txt">core5_latest_pretty.txt</a></li>
                <li><a href="ohlcv/binance/bootstrap.txt">bootstrap.txt</a></li>
                <li><a href="ohlcv/binance/core5_latest.json">core5_latest.json</a></li>
                <li><a href="ohlcv/binance/symbols.json">symbols.json</a></li>
              </ul>
            </body>
          </html>
          """
          with open("_site/start.html", "w", encoding="utf-8") as f:
            f.write(start_html)
          with open("_site/index.html", "w", encoding="utf-8") as f:
            f.write(start_html)

          print("OK:", updated_utc, "tail", TAIL)
          PY
        env:
          TAIL_LINES: ${{ github.event.inputs.tail_lines }}

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: _site

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
